#include "Google/Runtime/GoogleRuntime.h"
#include <iostream>
#include <iomanip>
#include <chrono>
#include <cmath>

using namespace google::runtime;

// External function generated by MLIR (from existing compiled code)
extern "C" {
  void matmul_l3_test(
    float* A_data, float* A_aligned, int64_t A_offset,
    int64_t A_size0, int64_t A_size1,
    int64_t A_stride0, int64_t A_stride1,
    float* B_data, float* B_aligned, int64_t B_offset,
    int64_t B_size0, int64_t B_size1,
    int64_t B_stride0, int64_t B_stride1,
    float* C_data, float* C_aligned, int64_t C_offset,
    int64_t C_size0, int64_t C_size1,
    int64_t C_stride0, int64_t C_stride1
  );
}

// Wrapper function for easier calling
void matmul_wrapper(void** args) {
    float* A = static_cast<float*>(args[0]);
    float* B = static_cast<float*>(args[1]);
    float* C = static_cast<float*>(args[2]);
    int64_t size = *static_cast<int64_t*>(args[3]);
    
    matmul_l3_test(
        A, A, 0, size, size, size, 1,
        B, B, 0, size, size, size, 1,
        C, C, 0, size, size, size, 1
    );
}

bool verify_result(const Tensor& C, int64_t size, float expected) {
    const float tolerance = 0.01f;
    for (int64_t i = 0; i < size; ++i) {
        for (int64_t j = 0; j < size; ++j) {
            if (std::abs(C(i, j) - expected) > tolerance) {
                std::cout << "  Error at (" << i << ", " << j << "): expected " 
                         << expected << ", got " << C(i, j) << std::endl;
                return false;
            }
        }
    }
    return true;
}

double benchmark_matmul(int64_t size, int iterations) {
    auto& runtime = GoogleRuntime::instance();
    
    // Create tensors using new Tensor class
    Tensor A({size, size});
    Tensor B({size, size});
    Tensor C({size, size});
    
    // Initialize with ones
    A.fill(1.0f);
    B.fill(1.0f);
    
    // Warm-up run
    std::vector<void*> args = {A.data(), B.data(), C.data(), &size};
    runtime.execute("matmul_l3", args);
    
    // Benchmark
    auto start = std::chrono::high_resolution_clock::now();
    for (int i = 0; i < iterations; ++i) {
        C.fill(0.0f);
        runtime.execute("matmul_l3", args);
    }
    auto end = std::chrono::high_resolution_clock::now();
    
    double total_ms = std::chrono::duration<double, std::milli>(end - start).count();
    return total_ms / iterations;
}

int main(int argc, char** argv) {
    std::cout << "\n=== Google Runtime Test (Phase 1) ===\n" << std::endl;
    
    // Get runtime instance
    auto& runtime = GoogleRuntime::instance();
    
    // Register the compiled kernel
    runtime.registerKernel("matmul_l3", reinterpret_cast<void*>(matmul_wrapper));
    
    std::cout << "Registered kernels: " << runtime.numKernels() << std::endl;
    std::cout << "Has matmul_l3: " << (runtime.hasKernel("matmul_l3") ? "yes" : "no") << std::endl;
    std::cout << std::endl;
    
    const int64_t SIZE = 1024;
    const int ITERATIONS = 5;
    
    std::cout << "Configuration:" << std::endl;
    std::cout << "  Matrix size: " << SIZE << "x" << SIZE << std::endl;
    std::cout << "  Iterations: " << ITERATIONS << std::endl;
    std::cout << "  Total FLOPs per matmul: " << (2.0 * SIZE * SIZE * SIZE) << std::endl;
    std::cout << std::endl;
    
    // Test correctness
    std::cout << "Testing correctness..." << std::endl;
    
    Tensor A({SIZE, SIZE});
    Tensor B({SIZE, SIZE});
    Tensor C({SIZE, SIZE});
    
    A.fill(1.0f);
    B.fill(1.0f);
    
    std::vector<void*> args = {A.data(), B.data(), C.data(), 
                              const_cast<int64_t*>(&SIZE)};
    runtime.execute("matmul_l3", args);
    
    float expected = static_cast<float>(SIZE);  // Sum of SIZE 1.0s
    bool correct = verify_result(C, SIZE, expected);
    
    if (correct) {
        std::cout << "  ✓ Correctness: PASS" << std::endl;
    } else {
        std::cout << "  ✗ Correctness: FAIL" << std::endl;
        return 1;
    }
    
    // Test eager operations
    std::cout << "\nTesting eager operations..." << std::endl;
    
    Tensor X({4, 4});
    X.fill(2.0f);
    
    Tensor Y = X / 2.0f;  // Should be all 1.0
    Tensor Z = Y.relu();  // Should be all 1.0
    
    std::cout << "  X / 2.0 = " << Y(0, 0) << " (expected 1.0)" << std::endl;
    std::cout << "  relu(Y) = " << Z(0, 0) << " (expected 1.0)" << std::endl;
    
    if (std::abs(Y(0, 0) - 1.0f) < 0.01f && std::abs(Z(0, 0) - 1.0f) < 0.01f) {
        std::cout << "  ✓ Eager operations: PASS" << std::endl;
    } else {
        std::cout << "  ✗ Eager operations: FAIL" << std::endl;
        return 1;
    }
    
    // Benchmark performance
    std::cout << "\nBenchmarking performance..." << std::endl;
    double avg_time_ms = benchmark_matmul(SIZE, ITERATIONS);
    
    double gflops = (2.0 * SIZE * SIZE * SIZE) / (avg_time_ms * 1e6);
    
    std::cout << std::fixed << std::setprecision(2);
    std::cout << "\nResults:" << std::endl;
    std::cout << "  Average time: " << avg_time_ms << " ms" << std::endl;
    std::cout << "  Performance: " << gflops << " GFLOPS" << std::endl;
    std::cout << std::endl;
    
    std::cout << "=== Phase 1 Runtime Test Complete ===\n" << std::endl;
    
    return 0;
}
